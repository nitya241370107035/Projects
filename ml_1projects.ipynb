{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad61de4f",
   "metadata": {},
   "source": [
    "scikit learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807c30ba",
   "metadata": {},
   "source": [
    "1: # üìà Linear Regression - Summary\n",
    "\n",
    "'''\n",
    "‚úÖ What is Linear Regression?\n",
    "- A supervised learning algorithm used for predicting a continuous output.\n",
    "- It finds the best-fitting straight line (y = mx + c) through the data points.\n",
    "\n",
    "üß™ How it Works:\n",
    "1. Assumes a linear relationship between input (X) and output (y).\n",
    "2. Tries to minimize the error (difference between actual and predicted values).\n",
    "3. Uses the **least squares method** to find the best-fit line.\n",
    "\n",
    "‚öôÔ∏è Main Code Steps:\n",
    "1. Import:\n",
    "   from sklearn.linear_model import LinearRegression\n",
    "2. Prepare data:\n",
    "   x = df[['feature']]        # Independent variable(s)\n",
    "   y = df[['target']]         # Dependent variable\n",
    "3. Train-test split:\n",
    "   from sklearn.model_selection import train_test_split\n",
    "   x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "4. Train model:\n",
    "   model = LinearRegression()\n",
    "   model.fit(x_train, y_train)\n",
    "5. Predict:\n",
    "   y_pred = model.predict(x_test)\n",
    "6. Evaluate:\n",
    "   from sklearn.metrics import mean_squared_error, r2_score\n",
    "   mse = mean_squared_error(y_test, y_pred)\n",
    "   r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "üéØ Key Points:\n",
    "- y = mx + c ‚Üí m = slope (coefficient), c = intercept\n",
    "- Good for predicting numerical values (e.g., price, temperature).\n",
    "- Sensitive to outliers.\n",
    "- Best for linearly related data.\n",
    "- Evaluate using metrics like **R¬≤ score**, **Mean Squared Error (MSE)**.\n",
    "\n",
    "üìå Use Cases:\n",
    "- Predicting house prices\n",
    "- Forecasting sales/revenue\n",
    "- Analyzing relationships (e.g., hours studied vs. exam score)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "743a5658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted exam score:[[88.80952381]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitya\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#step 1\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression \n",
    "\n",
    "#step 2\n",
    "\n",
    "student_data={'hour_study':[2,3,4,5,6,7,8,9,10],'exam_score':[50,60,70,75,80,85,90,93,95]}\n",
    "\n",
    "df=pd.DataFrame(student_data)\n",
    "\n",
    "#step 3 (store extracted feature in variable)\n",
    "\n",
    "x=df[['hour_study']]\n",
    "y=df[['exam_score']]\n",
    "\n",
    "#step 4 (test the stored features using 80:20 means 80% training and 20% testing for efficient model)\n",
    "\n",
    "x_train , x_test , y_train , y_test = train_test_split(x , y , test_size=0.2 , random_state=42) \n",
    "\n",
    "#creating instance for linear res to call as model\n",
    "\n",
    "model=LinearRegression()\n",
    "\n",
    "#training for x,y 80%\n",
    "\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "#user input testing\n",
    "\n",
    "user_input=float(input(\"enter number of hours you study:\"))\n",
    "\n",
    "#transfering predicting data to model\n",
    "\n",
    "predicted_score=model.predict([[user_input]])\n",
    "\n",
    "print(f\"predicted exam score:{predicted_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8900e8",
   "metadata": {},
   "source": [
    "2:# üîê Logistic Regression - Summary\n",
    "\n",
    "'''\n",
    "‚úÖ What is Logistic Regression?\n",
    "- A supervised classification algorithm.\n",
    "- Used to predict the probability of a binary (or multi-class) outcome.\n",
    "- Output is between 0 and 1 using the **sigmoid function**.\n",
    "\n",
    "üß™ How it Works:\n",
    "1. Takes input features (X) and applies linear equation: z = wx + b\n",
    "2. Passes z into the sigmoid function: sigmoid(z) = 1 / (1 + e^(-z))\n",
    "3. Outputs a probability ‚Üí class is 1 if prob > 0.5, else 0\n",
    "\n",
    "‚öôÔ∏è Main Code Steps:\n",
    "1. Import:\n",
    "   from sklearn.linear_model import LogisticRegression\n",
    "2. Prepare data:\n",
    "   x = df[['features']]\n",
    "   y = df['target']       # 0 or 1\n",
    "3. Split:\n",
    "   from sklearn.model_selection import train_test_split\n",
    "   x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "4. Train:\n",
    "   model = LogisticRegression()\n",
    "   model.fit(x_train, y_train)\n",
    "5. Predict:\n",
    "   y_pred = model.predict(x_test)\n",
    "6. Evaluate:\n",
    "   from sklearn.metrics import accuracy_score, classification_report\n",
    "   accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "üéØ Key Points:\n",
    "- Used for binary classification (0/1), or multi-class (with `multi_class='multinomial'`)\n",
    "- Uses sigmoid curve to model probabilities\n",
    "- Outputs class labels (0/1) and probabilities (with `predict_proba`)\n",
    "- Works best with linearly separable data\n",
    "- Evaluate using accuracy, precision, recall, F1-score\n",
    "\n",
    "üìå Use Cases:\n",
    "- Spam detection\n",
    "- Disease prediction (e.g., diabetes)\n",
    "- Customer churn prediction\n",
    "- Admission or purchase likelihood\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d525d8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 100.00%\n",
      "\n",
      "\n",
      " User is most likely to purchase!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Step 1: Input data\n",
    "x = np.array([[30, 25, 0], [30, 40, 1], [20, 35, 0], [35, 45, 1]])\n",
    "y = np.array([0, 1, 0, 1])\n",
    "\n",
    "# Step 2: Split data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Train model\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Step 4: Check accuracy\n",
    "accuracy = model.score(x_test, y_test)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\\n\")\n",
    "\n",
    "# Step 5: User input\n",
    "try:\n",
    "    user_age = float(input(\" Enter user age: \"))\n",
    "    user_time_spent = float(input(\" Enter time spent on website (in mins): \"))\n",
    "    user_add_cart = int(input(\" Enter 1 if user added to cart, else 0: \"))\n",
    "\n",
    "    user_data = np.array([[user_age, user_time_spent, user_add_cart]])\n",
    "\n",
    "    # Step 6: Prediction\n",
    "    prediction = model.predict(user_data)\n",
    "\n",
    "    # Step 7: Output result\n",
    "    if prediction[0] == 1:\n",
    "        print(\"\\n User is most likely to purchase!\")\n",
    "    else:\n",
    "        print(\"\\n User may not purchase (low chance).\")\n",
    "\n",
    "except ValueError:\n",
    "    print(\"\\n Invalid input. Please enter numbers only.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00104d64",
   "metadata": {},
   "source": [
    "# ‚öîÔ∏è Support Vector Machine (SVM) - Summary\n",
    "\n",
    "'''\n",
    "‚úÖ What is SVM?\n",
    "- A powerful supervised learning algorithm used for **classification** and **regression**.\n",
    "- Best for complex and high-dimensional datasets.\n",
    "- It finds the **best decision boundary (hyperplane)** that separates classes with the **maximum margin**.\n",
    "\n",
    "üß™ How it Works:\n",
    "1. Maps input data into high-dimensional space (if needed).\n",
    "2. Finds the **optimal hyperplane** that separates classes.\n",
    "3. Focuses on the **support vectors** ‚Äî the closest points to the boundary.\n",
    "4. Can use different **kernels** to handle non-linear data.\n",
    "\n",
    "‚öôÔ∏è Main Code Steps:\n",
    "1. Import:\n",
    "   from sklearn.svm import SVC    # for classification\n",
    "2. Prepare data:\n",
    "   x = df[['features']]\n",
    "   y = df['labels']\n",
    "3. Train-test split:\n",
    "   from sklearn.model_selection import train_test_split\n",
    "   x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "4. Train:\n",
    "   model = SVC(kernel='linear')   # try 'rbf', 'poly', etc.\n",
    "   model.fit(x_train, y_train)\n",
    "5. Predict:\n",
    "   y_pred = model.predict(x_test)\n",
    "6. Evaluate:\n",
    "   from sklearn.metrics import accuracy_score, classification_report\n",
    "   accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "üéØ Key Points:\n",
    "- **Kernel** trick allows handling non-linear data:\n",
    "  - 'linear', 'rbf' (Gaussian), 'poly', 'sigmoid'\n",
    "- Good for both small & large feature spaces\n",
    "- Not affected much by outliers\n",
    "- Focuses only on **support vectors** for decision-making\n",
    "- Can be slow on very large datasets\n",
    "\n",
    "üìå Use Cases:\n",
    "- Image classification\n",
    "- Bioinformatics (gene classification)\n",
    "- Text classification (e.g., spam vs. ham)\n",
    "- Handwriting recognition\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fc8d389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model Accuracy (linear kernel): 1.00\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         3\n",
      "   macro avg       1.00      1.00      1.00         3\n",
      "weighted avg       1.00      1.00      1.00         3\n",
      "\n",
      ">>user may leave<<\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Step 1: Simpler, pattern-based dataset\n",
    "data = {\n",
    "    'age': [18, 22, 25, 28, 31, 35, 40, 45, 50, 55, 60, 65],\n",
    "    'monthly_recharge': [10, 15, 18, 20, 25, 30, 100, 110, 115, 120, 130, 140],\n",
    "    'churn': [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]  # 0 for low recharge, 1 for high\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Step 2: Split features and labels\n",
    "x = df[['age', 'monthly_recharge']]\n",
    "y = df['churn']\n",
    "\n",
    "# Step 3: Scale features\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "\n",
    "# Step 4: Train-test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Step 5: Train SVM using linear kernel\n",
    "model = SVC(kernel='linear', C=1.0)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Step 6: Predict and evaluate\n",
    "y_pred = model.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\n Model Accuracy (linear kernel): {accuracy:.2f}\")\n",
    "print(\"\\n Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "#user input\n",
    "\n",
    "input_age=int(input(\"enter the value of your age\"))\n",
    "input_monthlycharge=float(input(\"enter the monthly charge\"))\n",
    "\n",
    "user_data=np.array([[input_age,input_monthlycharge]])\n",
    "\n",
    "prediction=model.predict(user_data)\n",
    "\n",
    "if prediction[0]==0:\n",
    "    print(\"the user will stay\")\n",
    "else:\n",
    "    print(\">>user may leave<<\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075e46ba",
   "metadata": {},
   "source": [
    "# üîç K-Nearest Neighbors (KNN) - Summary\n",
    "\n",
    "'''\n",
    "‚úÖ What is KNN?\n",
    "- KNN is a supervised machine learning algorithm.\n",
    "- Mostly used for classification; also works for regression.\n",
    "- It predicts the class of a new data point based on the majority class of its k-nearest neighbors.\n",
    "\n",
    "üß™ How it Works:\n",
    "1. Choose the number of neighbors (k).\n",
    "2. Calculate distance (usually Euclidean) between the new point and all training points.\n",
    "3. Select the k-nearest points.\n",
    "4. For classification ‚Üí Majority vote.\n",
    "   For regression ‚Üí Take average of neighbors.\n",
    "5. Output the result.\n",
    "\n",
    "‚öôÔ∏è Main Code Steps:\n",
    "1. Import:\n",
    "   from sklearn.neighbors import KNeighborsClassifier\n",
    "2. Scale data:\n",
    "   from sklearn.preprocessing import StandardScaler\n",
    "   scaler = StandardScaler()\n",
    "3. Split data:\n",
    "   from sklearn.model_selection import train_test_split\n",
    "4. Train:\n",
    "   knn = KNeighborsClassifier(n_neighbors=3)\n",
    "   knn.fit(x_train, y_train)\n",
    "5. Test & evaluate:\n",
    "   accuracy = knn.score(x_test, y_test)\n",
    "\n",
    "üéØ Key Points:\n",
    "- Small k = flexible but noisy (overfitting risk).\n",
    "- Large k = smoother but may underfit.\n",
    "- Distance metric: Default is Euclidean.\n",
    "- Data scaling is important.\n",
    "- KNN is a lazy learner: No actual training, stores data for prediction.\n",
    "\n",
    "üìå Use Cases:\n",
    "- Customer segmentation\n",
    "- Pattern recognition (handwriting, face)\n",
    "- Recommender systems\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729d23ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is:83.33333333333334%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 2. Data\n",
    "data = np.array([\n",
    "    [25, 40000, 2], [40, 70000, 1], [20, 30000, 2], [35, 60000, 3], [25, 50000, 1],\n",
    "    [20, 70000, 3], [28, 48000, 1], [32, 65000, 2], [22, 35000, 3], [27, 42000, 2],\n",
    "    [30, 52000, 1], [23, 45000, 2], [33, 62000, 3], [26, 49000, 2], [29, 53000, 1],\n",
    "    [31, 64000, 2], [21, 37000, 3], [24, 41000, 2], [34, 61000, 3], [36, 59000, 1],\n",
    "    [37, 58000, 2], [38, 57000, 1], [39, 56000, 2], [41, 54000, 3], [42, 55000, 1],\n",
    "    [43, 53000, 2], [44, 52000, 1], [45, 51000, 3], [46, 50000, 2], [47, 49000, 1]\n",
    "])\n",
    "labels = np.array([1, 0, 1, 2, 0, 2, 1, 2, 0, 1,\n",
    "                   1, 1, 2, 1, 1, 2, 0, 1, 2, 0,\n",
    "                   2, 0, 2, 2, 0, 2, 0, 2, 1, 0])#0>>low , 1>>medium , 2>>high\n",
    "\n",
    "# 3. Scale data\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "# 4. Train-test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_scaled, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "# 5. Train model\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "# 6. Test accuracy\n",
    "accuracy = knn.score(x_test, y_test)\n",
    "print(f\"Accuracy of the model is:{ (accuracy*100)}%\")\n",
    "\n",
    "#7. user input\n",
    "\n",
    "user_input=np.array([[45,80000,1]])\n",
    "user_input_scaled=scaler.transform(user_input)\n",
    "knn.predict(user_input_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cee15a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
